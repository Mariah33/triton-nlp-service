name: "translation"
backend: "python"
max_batch_size: 16

input [
  {
    name: "text"
    data_type: TYPE_STRING
    dims: [ 1 ]
  },
  {
    name: "source_language"
    data_type: TYPE_STRING
    dims: [ 1 ]
    optional: true
  },
  {
    name: "target_language"
    data_type: TYPE_STRING
    dims: [ 1 ]
    optional: true
  }
]

output [
  {
    name: "translated_text"
    data_type: TYPE_STRING
    dims: [ 1 ]
  }
]

instance_group [
  {
    count: 2
    kind: KIND_GPU
  }
]

parameters: {
  key: "EXECUTION_ENV_PATH",
  value: {string_value: "$$TRITON_MODEL_DIRECTORY/env.tar.gz"}
}

# Optimization parameters for transformer models
optimization {
  graph {
    level: 1
  }
}

# Dynamic batching for better throughput
dynamic_batching {
  preferred_batch_size: [ 4, 8 ]
  max_queue_delay_microseconds: 100
}
